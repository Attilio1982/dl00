{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reti neurali artificiali\n",
    "In questo notebook implementeremo la nostra prima rete neurale artificiale utilizzando Keras, lo scopo del nostro modello sarà sempre quello di identificare tumori al seno maligni, a questo scopo utilizzeremo il Winsconsis breast cancer dataset.\n",
    "<br><br>\n",
    "Importiamo i vari moduli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.initializers import RandomUniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carichiamo il Winsconsis breast cancer dataset all'interno di un DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "            ...             radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           ...                    25.38          17.33           184.60   \n",
       "1           ...                    24.99          23.41           158.80   \n",
       "2           ...                    23.57          25.53           152.50   \n",
       "3           ...                    14.91          26.50            98.87   \n",
       "4           ...                    22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\",\n",
    "                           names=[\"id\",\"diagnosis\",\"radius_mean\",\"texture_mean\",\"perimeter_mean\",\"area_mean\",\"smoothness_mean\",\"compactness_mean\",\"concavity_mean\",\"concave points_mean\",\"symmetry_mean\",\"fractal_dimension_mean\",\"radius_se\",\"texture_se\",\"perimeter_se\",\"area_se\",\"smoothness_se\",\"compactness_se\",\"concavity_se\",\"concave points_se\",\"symmetry_se\",\"fractal_dimension_se\",\"radius_worst\",\"texture_worst\",\"perimeter_worst\",\"area_worst\",\"smoothness_worst\",\"compactness_worst\",\"concavity_worst\",\"concave points_worst\",\"symmetry_worst\",\"fractal_dimension_worst\"])\n",
    "\n",
    "breast_cancer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo gli array numpy per addestrare e testare la nostra rete neurale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = breast_cancer.drop(['diagnosis','id'],axis=1).values\n",
    "Y = breast_cancer['diagnosis'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codifichiamo i label della nostra variabile target in numeri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizziamo gli array con le features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 12)                372       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 385\n",
      "Trainable params: 385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-2f6d2edceb2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \"\"\"\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpydot\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         raise ImportError(\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;34m'Failed to import `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;34m'Please install `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             'For example with `pip install pydot`.')\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`."
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "398/398 [==============================] - 0s 663us/step - loss: 0.9208 - acc: 0.4497\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.7352 - acc: 0.5704\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.6188 - acc: 0.6382\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.5408 - acc: 0.6784\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.4867 - acc: 0.7487\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.4475 - acc: 0.7864\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.4186 - acc: 0.8266\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.3948 - acc: 0.8568\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.3745 - acc: 0.8844\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.3572 - acc: 0.9095\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.3417 - acc: 0.9121\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.3275 - acc: 0.9196\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.3145 - acc: 0.9221\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.3023 - acc: 0.9271\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.2909 - acc: 0.9322\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.2800 - acc: 0.9397\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.2696 - acc: 0.9422\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.2596 - acc: 0.9447\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.2503 - acc: 0.9447\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.2415 - acc: 0.9472\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.2333 - acc: 0.9472\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.2254 - acc: 0.9497\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.2181 - acc: 0.9523\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.2110 - acc: 0.9523\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.2044 - acc: 0.9523\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.1983 - acc: 0.9523\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.1925 - acc: 0.9523\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.1872 - acc: 0.9523\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.1821 - acc: 0.9523\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.1773 - acc: 0.9523\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.1728 - acc: 0.9523\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.1687 - acc: 0.9523\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.1647 - acc: 0.9523\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.1609 - acc: 0.9548\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.1574 - acc: 0.9548\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.1541 - acc: 0.9523\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.1511 - acc: 0.9523\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 0s 34us/step - loss: 0.1481 - acc: 0.9523\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 0s 47us/step - loss: 0.1454 - acc: 0.9523\n",
      "Epoch 40/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.1428 - acc: 0.9523\n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.1403 - acc: 0.9573\n",
      "Epoch 42/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.1380 - acc: 0.9573\n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.1358 - acc: 0.9573\n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.1337 - acc: 0.9573\n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.1317 - acc: 0.9573\n",
      "Epoch 46/100\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.1298 - acc: 0.9573\n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.1279 - acc: 0.9598\n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 0s 47us/step - loss: 0.1262 - acc: 0.9598\n",
      "Epoch 49/100\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.1246 - acc: 0.9598\n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.1229 - acc: 0.9598\n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.1214 - acc: 0.9598\n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.1200 - acc: 0.9598\n",
      "Epoch 53/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.1186 - acc: 0.9598\n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.1173 - acc: 0.9598\n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.1159 - acc: 0.9623\n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.1146 - acc: 0.9623\n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.1134 - acc: 0.9623\n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.1122 - acc: 0.9623\n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.1111 - acc: 0.9623\n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.1100 - acc: 0.9623\n",
      "Epoch 61/100\n",
      "398/398 [==============================] - 0s 49us/step - loss: 0.1090 - acc: 0.9623\n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.1079 - acc: 0.9623\n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.1070 - acc: 0.9623\n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.1060 - acc: 0.9623\n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.1051 - acc: 0.9623\n",
      "Epoch 66/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.1042 - acc: 0.9648\n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.1034 - acc: 0.9648\n",
      "Epoch 68/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.1024 - acc: 0.9648\n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.1015 - acc: 0.9673\n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.1008 - acc: 0.9673\n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.0999 - acc: 0.9673\n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.0992 - acc: 0.9673\n",
      "Epoch 73/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.0984 - acc: 0.9673\n",
      "Epoch 74/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.0977 - acc: 0.9698\n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.0969 - acc: 0.9698\n",
      "Epoch 76/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.0962 - acc: 0.9698\n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.0956 - acc: 0.9698\n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.0949 - acc: 0.9698\n",
      "Epoch 79/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.0943 - acc: 0.9698\n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0936 - acc: 0.9698\n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.0930 - acc: 0.9698\n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.0924 - acc: 0.9724\n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.0918 - acc: 0.9724\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 0s 44us/step - loss: 0.0912 - acc: 0.9749\n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.0906 - acc: 0.9749\n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.0899 - acc: 0.9749\n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.0893 - acc: 0.9749\n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.0887 - acc: 0.9749\n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.0881 - acc: 0.9774\n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.0875 - acc: 0.9774\n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.0869 - acc: 0.9799\n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.0864 - acc: 0.9799\n",
      "Epoch 93/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.0858 - acc: 0.9799\n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.0853 - acc: 0.9799\n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.0848 - acc: 0.9799\n",
      "Epoch 96/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0843 - acc: 0.9799\n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0838 - acc: 0.9799\n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0833 - acc: 0.9799\n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0828 - acc: 0.9799\n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0824 - acc: 0.9799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2a315a20>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s 455us/step\n",
      "Loss sul test set: 0.1074\n",
      "Accuracy sul test set: 0.9532\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Loss sul test set: %.4f\" % loss)\n",
    "print(\"Accuracy sul test set: %.4f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reti neurali artificiali profonde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(12, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dense(4, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 12)                372       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 517\n",
      "Trainable params: 517\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.7294 - acc: 0.5126\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.6957 - acc: 0.6407\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.6763 - acc: 0.6935\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.6615 - acc: 0.7437\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 0s 49us/step - loss: 0.6475 - acc: 0.7814\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 0s 49us/step - loss: 0.6331 - acc: 0.8040\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 0.6172 - acc: 0.8166\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.6003 - acc: 0.8266\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 0s 51us/step - loss: 0.5821 - acc: 0.8417\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 0s 47us/step - loss: 0.5623 - acc: 0.8442\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 0s 55us/step - loss: 0.5408 - acc: 0.8643\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 0.5178 - acc: 0.8744\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 0s 54us/step - loss: 0.4929 - acc: 0.8819\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 0.4665 - acc: 0.8869\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 0s 52us/step - loss: 0.4390 - acc: 0.8970\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 0s 52us/step - loss: 0.4121 - acc: 0.8995\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 0s 51us/step - loss: 0.3851 - acc: 0.9020\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 0s 52us/step - loss: 0.3588 - acc: 0.9121\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 0s 55us/step - loss: 0.3338 - acc: 0.9171\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 0.3107 - acc: 0.9246\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 0s 49us/step - loss: 0.2893 - acc: 0.9296\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 0.2701 - acc: 0.9322\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 0s 51us/step - loss: 0.2529 - acc: 0.9372\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 0.2375 - acc: 0.9372\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.2237 - acc: 0.9397\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 0s 56us/step - loss: 0.2116 - acc: 0.9372\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 0s 55us/step - loss: 0.2007 - acc: 0.9447\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 0s 55us/step - loss: 0.1910 - acc: 0.9447\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 0s 61us/step - loss: 0.1822 - acc: 0.9497\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 0s 58us/step - loss: 0.1744 - acc: 0.9497\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 0s 63us/step - loss: 0.1673 - acc: 0.9497\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 0s 58us/step - loss: 0.1609 - acc: 0.9497\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 0s 52us/step - loss: 0.1549 - acc: 0.9523\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.1494 - acc: 0.9523\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.1445 - acc: 0.9548\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.1400 - acc: 0.9548\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.1358 - acc: 0.9573\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.1319 - acc: 0.9598\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.1283 - acc: 0.9598\n",
      "Epoch 40/100\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.1249 - acc: 0.9623\n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.1218 - acc: 0.9623\n",
      "Epoch 42/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.1191 - acc: 0.9648\n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 0s 49us/step - loss: 0.1163 - acc: 0.9648\n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 0s 51us/step - loss: 0.1138 - acc: 0.9673\n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.1115 - acc: 0.9698\n",
      "Epoch 46/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.1093 - acc: 0.9724\n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.1072 - acc: 0.9724\n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.1054 - acc: 0.9749\n",
      "Epoch 49/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.1035 - acc: 0.9774\n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 0s 52us/step - loss: 0.1019 - acc: 0.9774\n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 0s 52us/step - loss: 0.1003 - acc: 0.9774\n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.0989 - acc: 0.9774\n",
      "Epoch 53/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.0976 - acc: 0.9799\n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.0963 - acc: 0.9799\n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.0951 - acc: 0.9799\n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 0s 52us/step - loss: 0.0939 - acc: 0.9799\n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.0928 - acc: 0.9799\n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.0917 - acc: 0.9774\n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.0907 - acc: 0.9774\n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0898 - acc: 0.9774\n",
      "Epoch 61/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0890 - acc: 0.9774\n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0881 - acc: 0.9774\n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.0873 - acc: 0.9774\n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.0865 - acc: 0.9774\n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.0858 - acc: 0.9774\n",
      "Epoch 66/100\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.0851 - acc: 0.9774\n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0844 - acc: 0.9774\n",
      "Epoch 68/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0837 - acc: 0.9774\n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.0831 - acc: 0.9774\n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.0825 - acc: 0.9774\n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0819 - acc: 0.9774\n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0813 - acc: 0.9774\n",
      "Epoch 73/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0807 - acc: 0.9774\n",
      "Epoch 74/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.0802 - acc: 0.9774\n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0797 - acc: 0.9774\n",
      "Epoch 76/100\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0792 - acc: 0.9774\n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 0s 34us/step - loss: 0.0787 - acc: 0.9774\n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0782 - acc: 0.9774\n",
      "Epoch 79/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.0778 - acc: 0.9774\n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0774 - acc: 0.9799\n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.0770 - acc: 0.9799\n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0766 - acc: 0.9799\n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0762 - acc: 0.9799\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 0s 43us/step - loss: 0.0759 - acc: 0.9799\n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.0755 - acc: 0.9799\n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.0751 - acc: 0.9799\n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.0748 - acc: 0.9799\n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.0744 - acc: 0.9799\n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0740 - acc: 0.9799\n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0737 - acc: 0.9799\n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.0734 - acc: 0.9799\n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0731 - acc: 0.9799\n",
      "Epoch 93/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.0728 - acc: 0.9799\n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0726 - acc: 0.9799\n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.0723 - acc: 0.9799\n",
      "Epoch 96/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0720 - acc: 0.9799\n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0718 - acc: 0.9799\n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 0s 49us/step - loss: 0.0715 - acc: 0.9799\n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.0712 - acc: 0.9799\n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.0710 - acc: 0.9799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1195090b8>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s 808us/step\n",
      "Loss sul test set: 0.0615\n",
      "Accuracy sul test set: 0.9825\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Loss sul test set: %.4f\" % loss)\n",
    "print(\"Accuracy sul test set: %.4f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice di confusione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from viz import plot_confusion_matrix\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plot_confusion_matrix(cm,[\"benigno\", \"maligno\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 4.1304 - acc: 0.6181\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.6387 - acc: 0.5955\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.5802 - acc: 0.6131\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 0.5222 - acc: 0.6181\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 0.4750 - acc: 0.6206\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 0.4704 - acc: 0.6759\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 0.4325 - acc: 0.8668\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 0s 58us/step - loss: 0.3980 - acc: 0.8970\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 0s 59us/step - loss: 0.3694 - acc: 0.9196\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 0s 58us/step - loss: 0.3441 - acc: 0.9171\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 0s 51us/step - loss: 0.3204 - acc: 0.9296\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 0s 57us/step - loss: 0.2976 - acc: 0.9271\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 0s 61us/step - loss: 0.2777 - acc: 0.9322\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 0s 60us/step - loss: 0.2564 - acc: 0.9347\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 0s 74us/step - loss: 0.2370 - acc: 0.9472\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 0s 62us/step - loss: 0.2191 - acc: 0.9472\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 0s 59us/step - loss: 0.2026 - acc: 0.9548\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 0s 55us/step - loss: 0.1887 - acc: 0.9548\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 0s 58us/step - loss: 0.1752 - acc: 0.9623\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 0s 60us/step - loss: 0.1632 - acc: 0.9573\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 0s 56us/step - loss: 0.1538 - acc: 0.9623\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 0s 60us/step - loss: 0.1515 - acc: 0.9673\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 0s 58us/step - loss: 0.1476 - acc: 0.9698\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 0s 52us/step - loss: 0.5308 - acc: 0.6759\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 0s 56us/step - loss: 0.4378 - acc: 0.9271\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 0s 56us/step - loss: 0.3610 - acc: 0.9548\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 0s 58us/step - loss: 0.2529 - acc: 0.9724\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.1915 - acc: 0.9774\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 0s 56us/step - loss: 0.1727 - acc: 0.9749\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 0s 52us/step - loss: 0.1579 - acc: 0.9698\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 0s 58us/step - loss: 0.1448 - acc: 0.9724\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 0s 56us/step - loss: 0.1337 - acc: 0.9724\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 0s 58us/step - loss: 0.1231 - acc: 0.9698\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 0s 60us/step - loss: 0.1108 - acc: 0.9749\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 0s 59us/step - loss: 0.1019 - acc: 0.9749\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 0s 60us/step - loss: 0.1001 - acc: 0.9749\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 0s 59us/step - loss: 0.0979 - acc: 0.9749\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 0s 58us/step - loss: 0.0962 - acc: 0.9749\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 0s 52us/step - loss: 0.0948 - acc: 0.9749\n",
      "Epoch 40/100\n",
      "398/398 [==============================] - 0s 55us/step - loss: 0.0937 - acc: 0.9774\n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 0s 54us/step - loss: 0.0925 - acc: 0.9749\n",
      "Epoch 42/100\n",
      "398/398 [==============================] - 0s 59us/step - loss: 0.0917 - acc: 0.9774\n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.0905 - acc: 0.9774\n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 0s 58us/step - loss: 0.0890 - acc: 0.9774\n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 0s 54us/step - loss: 0.0882 - acc: 0.9799\n",
      "Epoch 46/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.0871 - acc: 0.9799\n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 0s 62us/step - loss: 0.0859 - acc: 0.9799\n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 0s 56us/step - loss: 0.0851 - acc: 0.9799\n",
      "Epoch 49/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.0839 - acc: 0.9799\n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 0.0831 - acc: 0.9799\n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 0s 54us/step - loss: 0.0820 - acc: 0.9799\n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 0s 51us/step - loss: 0.0814 - acc: 0.9799\n",
      "Epoch 53/100\n",
      "398/398 [==============================] - 0s 49us/step - loss: 0.0804 - acc: 0.9799\n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.0796 - acc: 0.9799\n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.0788 - acc: 0.9824\n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 0s 64us/step - loss: 0.0779 - acc: 0.9824\n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 0s 58us/step - loss: 0.0773 - acc: 0.9824\n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 0s 57us/step - loss: 0.0767 - acc: 0.9824\n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 0s 52us/step - loss: 0.0763 - acc: 0.9824\n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 0s 49us/step - loss: 0.0756 - acc: 0.9824\n",
      "Epoch 61/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.0747 - acc: 0.9824\n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.0742 - acc: 0.9824\n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.0738 - acc: 0.9824\n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 0s 47us/step - loss: 0.0734 - acc: 0.9824\n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 0s 49us/step - loss: 0.0729 - acc: 0.9824\n",
      "Epoch 66/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.0722 - acc: 0.9824\n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 0s 49us/step - loss: 0.0720 - acc: 0.9824\n",
      "Epoch 68/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.0713 - acc: 0.9824\n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 0s 49us/step - loss: 0.0711 - acc: 0.9824\n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.0705 - acc: 0.9824\n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.0701 - acc: 0.9824\n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 0s 51us/step - loss: 0.0700 - acc: 0.9824\n",
      "Epoch 73/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.0693 - acc: 0.9824\n",
      "Epoch 74/100\n",
      "398/398 [==============================] - 0s 51us/step - loss: 0.0689 - acc: 0.9824\n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 0s 47us/step - loss: 0.0686 - acc: 0.9824\n",
      "Epoch 76/100\n",
      "398/398 [==============================] - 0s 47us/step - loss: 0.0681 - acc: 0.9824\n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 0s 49us/step - loss: 0.0680 - acc: 0.9824\n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 0s 51us/step - loss: 0.0676 - acc: 0.9824\n",
      "Epoch 79/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.0672 - acc: 0.9824\n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.0667 - acc: 0.9824\n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 0s 52us/step - loss: 0.0666 - acc: 0.9824\n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.0663 - acc: 0.9824\n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 0s 54us/step - loss: 0.0659 - acc: 0.9824\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 0s 49us/step - loss: 0.0658 - acc: 0.9824\n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 0s 52us/step - loss: 0.0653 - acc: 0.9849\n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.0651 - acc: 0.9824\n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 0s 47us/step - loss: 0.0648 - acc: 0.9824\n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 0s 49us/step - loss: 0.0645 - acc: 0.9824\n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 0s 47us/step - loss: 0.0644 - acc: 0.9824\n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.0641 - acc: 0.9824\n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 0s 52us/step - loss: 0.0637 - acc: 0.9849\n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.0635 - acc: 0.9824\n",
      "Epoch 93/100\n",
      "398/398 [==============================] - 0s 47us/step - loss: 0.0634 - acc: 0.9849\n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 0s 49us/step - loss: 0.0631 - acc: 0.9824\n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.0629 - acc: 0.9849\n",
      "Epoch 96/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.0626 - acc: 0.9824\n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.0623 - acc: 0.9849\n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 0.0620 - acc: 0.9849\n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 0.0618 - acc: 0.9849\n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 0s 51us/step - loss: 0.0617 - acc: 0.9824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a30d5ccf8>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(12, input_dim=X_train.shape[1], activation=LeakyReLU(alpha=0.01)))\n",
    "model.add(Dense(8, activation=LeakyReLU(alpha=0.01)))\n",
    "model.add(Dense(4, activation=LeakyReLU(alpha=0.01)))\n",
    "model.add(Dense(1, activation=LeakyReLU(alpha=0.01)))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s 1ms/step\n",
      "Loss sul test set: 0.0484\n",
      "Accuracy sul test set: 0.9883\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Loss sul test set: %.4f\" % loss)\n",
    "print(\"Accuracy sul test set: %.4f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
