{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reti neurali artificiali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "            ...             radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           ...                    25.38          17.33           184.60   \n",
       "1           ...                    24.99          23.41           158.80   \n",
       "2           ...                    23.57          25.53           152.50   \n",
       "3           ...                    14.91          26.50            98.87   \n",
       "4           ...                    22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\",\n",
    "                           names=[\"id\",\"diagnosis\",\"radius_mean\",\"texture_mean\",\"perimeter_mean\",\"area_mean\",\"smoothness_mean\",\"compactness_mean\",\"concavity_mean\",\"concave points_mean\",\"symmetry_mean\",\"fractal_dimension_mean\",\"radius_se\",\"texture_se\",\"perimeter_se\",\"area_se\",\"smoothness_se\",\"compactness_se\",\"concavity_se\",\"concave points_se\",\"symmetry_se\",\"fractal_dimension_se\",\"radius_worst\",\"texture_worst\",\"perimeter_worst\",\"area_worst\",\"smoothness_worst\",\"compactness_worst\",\"concavity_worst\",\"concave points_worst\",\"symmetry_worst\",\"fractal_dimension_worst\"])\n",
    "\n",
    "breast_cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = breast_cancer.drop(['diagnosis','id'],axis=1).values\n",
    "Y = breast_cancer['diagnosis'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(Y_train)\n",
    "y_test = le.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(12, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 16)                496       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 693\n",
      "Trainable params: 693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "398/398 [==============================] - 0s 504us/step - loss: 0.6940 - acc: 0.6533\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.5660 - acc: 0.7487\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.4900 - acc: 0.8065\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.4386 - acc: 0.8467\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.3999 - acc: 0.8693\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.3698 - acc: 0.9045\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 0s 47us/step - loss: 0.3450 - acc: 0.9121\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 0s 52us/step - loss: 0.3250 - acc: 0.9221\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.3083 - acc: 0.9296\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 0s 54us/step - loss: 0.2932 - acc: 0.9322\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.2799 - acc: 0.9447\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 0s 32us/step - loss: 0.2679 - acc: 0.9447\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.2572 - acc: 0.9447\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.2477 - acc: 0.9497\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.2389 - acc: 0.9497\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 0s 47us/step - loss: 0.2309 - acc: 0.9497\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.2234 - acc: 0.9497\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.2166 - acc: 0.9523\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.2103 - acc: 0.9523\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.2046 - acc: 0.9548\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.1991 - acc: 0.9548\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.1940 - acc: 0.9573\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.1891 - acc: 0.9598\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.1846 - acc: 0.9623\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.1802 - acc: 0.9623\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 0s 49us/step - loss: 0.1761 - acc: 0.9648\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 0s 47us/step - loss: 0.1722 - acc: 0.9648\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.1685 - acc: 0.9673\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.1650 - acc: 0.9673\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.1616 - acc: 0.9673\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.1584 - acc: 0.9673\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.1555 - acc: 0.9673\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.1527 - acc: 0.9698\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.1499 - acc: 0.9698\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.1475 - acc: 0.9698\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.1450 - acc: 0.9698\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.1428 - acc: 0.9698\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.1405 - acc: 0.9698\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.1384 - acc: 0.9698\n",
      "Epoch 40/100\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.1364 - acc: 0.9698\n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.1345 - acc: 0.9698\n",
      "Epoch 42/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.1327 - acc: 0.9698\n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 0s 31us/step - loss: 0.1309 - acc: 0.9698\n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.1292 - acc: 0.9698\n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 0s 31us/step - loss: 0.1276 - acc: 0.9698\n",
      "Epoch 46/100\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.1259 - acc: 0.9698\n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 0s 32us/step - loss: 0.1245 - acc: 0.9698\n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.1229 - acc: 0.9698\n",
      "Epoch 49/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.1215 - acc: 0.9724\n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.1202 - acc: 0.9724\n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.1188 - acc: 0.9724\n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.1176 - acc: 0.9749\n",
      "Epoch 53/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.1164 - acc: 0.9749\n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.1152 - acc: 0.9749\n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.1141 - acc: 0.9749\n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.1130 - acc: 0.9749\n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 0s 31us/step - loss: 0.1119 - acc: 0.9749\n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.1108 - acc: 0.9749\n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.1098 - acc: 0.9749\n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.1088 - acc: 0.9749\n",
      "Epoch 61/100\n",
      "398/398 [==============================] - 0s 34us/step - loss: 0.1079 - acc: 0.9749\n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.1070 - acc: 0.9749\n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.1061 - acc: 0.9749\n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.1053 - acc: 0.9749\n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.1044 - acc: 0.9749\n",
      "Epoch 66/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.1037 - acc: 0.9749\n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.1029 - acc: 0.9774\n",
      "Epoch 68/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.1021 - acc: 0.9774\n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.1014 - acc: 0.9774\n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 0s 32us/step - loss: 0.1006 - acc: 0.9774\n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0999 - acc: 0.9774\n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 0s 33us/step - loss: 0.0993 - acc: 0.9774\n",
      "Epoch 73/100\n",
      "398/398 [==============================] - 0s 31us/step - loss: 0.0985 - acc: 0.9774\n",
      "Epoch 74/100\n",
      "398/398 [==============================] - 0s 34us/step - loss: 0.0979 - acc: 0.9774\n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 0s 31us/step - loss: 0.0972 - acc: 0.9774\n",
      "Epoch 76/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.0966 - acc: 0.9774\n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.0960 - acc: 0.9774\n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.0954 - acc: 0.9774\n",
      "Epoch 79/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.0948 - acc: 0.9774\n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0942 - acc: 0.9774\n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0937 - acc: 0.9774\n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0931 - acc: 0.9774\n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0925 - acc: 0.9774\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 0s 34us/step - loss: 0.0920 - acc: 0.9774\n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0914 - acc: 0.9774\n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0909 - acc: 0.9774\n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 0s 36us/step - loss: 0.0904 - acc: 0.9774\n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 0s 34us/step - loss: 0.0899 - acc: 0.9774\n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0894 - acc: 0.9774\n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0889 - acc: 0.9774\n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0885 - acc: 0.9774\n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.0880 - acc: 0.9774\n",
      "Epoch 93/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0875 - acc: 0.9774\n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0871 - acc: 0.9774\n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0867 - acc: 0.9774\n",
      "Epoch 96/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.0862 - acc: 0.9774\n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 0s 35us/step - loss: 0.0858 - acc: 0.9774\n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0854 - acc: 0.9774\n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.0850 - acc: 0.9774\n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.0846 - acc: 0.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a25354a90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s 304us/step\n",
      "Loss sul test set: 0.1007\n",
      "Accuracy sul test set: 0.9649\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Loss sul test set: %.4f\" % loss)\n",
    "print(\"Accuracy sul test set: %.4f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reti neurali artificiali profonde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dense(6, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 16)                496       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 693\n",
      "Trainable params: 693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "398/398 [==============================] - 0s 846us/step - loss: 0.8015 - acc: 0.4221\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.7037 - acc: 0.5402\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - 0s 47us/step - loss: 0.6367 - acc: 0.6407\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 0s 56us/step - loss: 0.5813 - acc: 0.7286\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 0s 55us/step - loss: 0.5283 - acc: 0.8166\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 0s 58us/step - loss: 0.4788 - acc: 0.8417\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 0.4328 - acc: 0.8719\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 0s 49us/step - loss: 0.3917 - acc: 0.8894\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 0s 47us/step - loss: 0.3570 - acc: 0.8970\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 0s 56us/step - loss: 0.3269 - acc: 0.9020\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 0.3023 - acc: 0.9095\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 0s 51us/step - loss: 0.2809 - acc: 0.9121\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.2614 - acc: 0.9171\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 0s 55us/step - loss: 0.2450 - acc: 0.9246\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.2302 - acc: 0.9246\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 0s 54us/step - loss: 0.2170 - acc: 0.9271\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.2048 - acc: 0.9372\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.1943 - acc: 0.9397\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 0s 56us/step - loss: 0.1849 - acc: 0.9422\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.1764 - acc: 0.9472\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 0s 52us/step - loss: 0.1688 - acc: 0.9472\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 0s 52us/step - loss: 0.1618 - acc: 0.9497\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.1555 - acc: 0.9523\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.1495 - acc: 0.9523\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 0s 49us/step - loss: 0.1440 - acc: 0.9548\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.1392 - acc: 0.9573\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.1347 - acc: 0.9598\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.1306 - acc: 0.9623\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 0s 47us/step - loss: 0.1264 - acc: 0.9648\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 0s 52us/step - loss: 0.1227 - acc: 0.9698\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.1192 - acc: 0.9698\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.1156 - acc: 0.9724\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.1124 - acc: 0.9724\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.1091 - acc: 0.9749\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 0s 54us/step - loss: 0.1064 - acc: 0.9774\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 0s 52us/step - loss: 0.1037 - acc: 0.9774\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.1013 - acc: 0.9774\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 0s 55us/step - loss: 0.0991 - acc: 0.9774\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 0s 51us/step - loss: 0.0970 - acc: 0.9774\n",
      "Epoch 40/100\n",
      "398/398 [==============================] - 0s 57us/step - loss: 0.0952 - acc: 0.9799\n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 0s 52us/step - loss: 0.0933 - acc: 0.9799\n",
      "Epoch 42/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.0916 - acc: 0.9799\n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0901 - acc: 0.9799\n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 0s 55us/step - loss: 0.0886 - acc: 0.9799\n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 0s 52us/step - loss: 0.0873 - acc: 0.9799\n",
      "Epoch 46/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.0859 - acc: 0.9799\n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.0848 - acc: 0.9799\n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 0s 54us/step - loss: 0.0836 - acc: 0.9799\n",
      "Epoch 49/100\n",
      "398/398 [==============================] - 0s 47us/step - loss: 0.0825 - acc: 0.9799\n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0815 - acc: 0.9799\n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 0s 51us/step - loss: 0.0804 - acc: 0.9799\n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.0796 - acc: 0.9799\n",
      "Epoch 53/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.0785 - acc: 0.9799\n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.0776 - acc: 0.9799\n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.0768 - acc: 0.9799\n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 0.0760 - acc: 0.9799\n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.0751 - acc: 0.9824\n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 0s 51us/step - loss: 0.0743 - acc: 0.9799\n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.0736 - acc: 0.9799\n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 0s 51us/step - loss: 0.0727 - acc: 0.9799\n",
      "Epoch 61/100\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.0721 - acc: 0.9799\n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 0s 47us/step - loss: 0.0713 - acc: 0.9799\n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.0706 - acc: 0.9799\n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.0700 - acc: 0.9799\n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 0s 47us/step - loss: 0.0692 - acc: 0.9799\n",
      "Epoch 66/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.0688 - acc: 0.9799\n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 0s 44us/step - loss: 0.0680 - acc: 0.9799\n",
      "Epoch 68/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.0675 - acc: 0.9799\n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.0669 - acc: 0.9799\n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.0664 - acc: 0.9799\n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0659 - acc: 0.9799\n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 0s 49us/step - loss: 0.0653 - acc: 0.9799\n",
      "Epoch 73/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.0648 - acc: 0.9799\n",
      "Epoch 74/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.0642 - acc: 0.9799\n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.0637 - acc: 0.9799\n",
      "Epoch 76/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.0633 - acc: 0.9824\n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.0628 - acc: 0.9824\n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.0622 - acc: 0.9824\n",
      "Epoch 79/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.0619 - acc: 0.9824\n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.0614 - acc: 0.9849\n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.0609 - acc: 0.9849\n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.0605 - acc: 0.9849\n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0601 - acc: 0.9849\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 0s 40us/step - loss: 0.0597 - acc: 0.9849\n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.0592 - acc: 0.9849\n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.0589 - acc: 0.9849\n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 0s 39us/step - loss: 0.0584 - acc: 0.9849\n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.0580 - acc: 0.9849\n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 0s 47us/step - loss: 0.0577 - acc: 0.9849\n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.0572 - acc: 0.9849\n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.0569 - acc: 0.9849\n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.0565 - acc: 0.9849\n",
      "Epoch 93/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.0561 - acc: 0.9849\n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.0556 - acc: 0.9849\n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.0554 - acc: 0.9849\n",
      "Epoch 96/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.0550 - acc: 0.9849\n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 0s 37us/step - loss: 0.0546 - acc: 0.9849\n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 0.0543 - acc: 0.9849\n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 0s 41us/step - loss: 0.0540 - acc: 0.9849\n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 0s 42us/step - loss: 0.0536 - acc: 0.9849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2df72dd8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s 569us/step\n",
      "Loss sul test set: 0.0606\n",
      "Accuracy sul test set: 0.9766\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Loss sul test set: %.4f\" % loss)\n",
    "print(\"Accuracy sul test set: %.4f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice di confusione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[105   3]\n",
      " [  1  62]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEYCAYAAADLZOR0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xm8XeO9x/HP95wYQhIRMU9Bg5JrSEINRZS6KA11XdQQBOWqDjrRak0duLe3GsOlVAlaY6kWRapN1BSSiEpMMU8hiUhEZM7v/rGek6wcJ2fvnLP32cP5vvNar733Wms/67fPzvmd53nWs56liMDMzDINlQ7AzKyaOCmameU4KZqZ5TgpmpnlOCmameU4KZqZ5TgpWlEkdZX0F0kzJd3ejnKOlvRgKWOrFEl7SHqx0nFYacnjFOuLpK8CZwJbA7OA8cDPIuKRdpZ7LHAGsFtELGx3oFVOUgB9I+LlSsdiHcs1xToi6Uzg18DPgXWBTYD/AwaXoPhNgZc6Q0IshqQulY7ByiQivNTBAqwBfAwc3so+q5AlzXfT8mtglbRtEPA28B1gCjAZOCFtOx+YDyxIxxgKnAfclCu7DxBAl/T6eOBVstrqa8DRufWP5N63G/AUMDM97pbbNhK4EHg0lfMg0Hs5n60p/u/n4j8EOBB4CZgO/DC3/87A48CMtO/lwMpp28Pps8xOn/eIXPk/AN4Dbmxal96zRTpG//R6A2AaMKjS/ze8rNjimmL92BVYFbirlX1+BOwC7ABsT5YYzsltX48suW5IlviukLRmRJxLVvu8NSK6RcS1rQUiaXXgUuCAiOhOlvjGt7BfL+DetO9awK+AeyWtldvtq8AJwDrAysB3Wzn0emQ/gw2BnwDXAMcAA4A9gJ9I2jztuwj4NtCb7Ge3D/BfABGxZ9pn+/R5b82V34us1nxK/sAR8QpZwvy9pNWA64DrI2JkK/FaFXJSrB9rAdOi9ebt0cAFETElIqaS1QCPzW1fkLYviIj7yGpJW7UxnsVAP0ldI2JyRExsYZ8vAZMi4saIWBgRNwMvAAfn9rkuIl6KiDnAbWQJfXkWkPWfLgBuIUt4wyJiVjr+RGA7gIgYGxFPpOO+DvwG2KuIz3RuRMxL8SwjIq4BJgGjgfXJ/ghZjXFSrB8fAL0L9HVtALyRe/1GWrekjGZJ9ROg24oGEhGzyZqcpwKTJd0raesi4mmKacPc6/dWIJ4PImJRet6UtN7PbZ/T9H5JW0q6R9J7kj4iqwn3bqVsgKkRMbfAPtcA/YDLImJegX2tCjkp1o/Hgblk/WjL8y5Z06/JJmldW8wGVsu9Xi+/MSIeiIgvktWYXiBLFoXiaYrpnTbGtCKuJIurb0T0AH4IqMB7Wh2qIakbWT/ttcB5qXvAaoyTYp2IiJlk/WhXSDpE0mqSVpJ0gKT/TrvdDJwjaW1JvdP+N7XxkOOBPSVtImkN4OymDZLWlfTl1Lc4j6wZvqiFMu4DtpT0VUldJB0BbAPc08aYVkR34CPg41SLPa3Z9veBzT/1rtYNA8ZGxElkfaVXtTtK63BOinUkIn5FNkbxHGAq8BbwdeBPaZefAmOAfwHPAuPSurYcawRwayprLMsmsgays9jvkp2R3Yt0EqNZGR8AB6V9PyA7c3xQRExrS0wr6LtkJ3FmkdVib222/TxguKQZkv6zUGGSBgP7k3UZQPY99Jd0dMkitg7hwdtmZjmuKZqZ5TgpmpnlOCmameU4KZqZ5fii9haoS9fQyt0rHUantsNnN6l0CJ3am2+8zrRp0wqN2yxaY49NIxZ+6iKgT4k5Ux+IiP1Lddy2cFJsgVbuzipbFRyFYWX08GOXVjqETm3P3XYuaXmxcE5Rv1Nzx19R6KqisnNSNLPyk6ChsdJRFMVJ0cw6hmrjFIaTopl1DJWsi7KsnBTNrAO4+WxmtpSomeZzbURpZjVOWfO50FKoFOl3kqZImpBb10vSCEmT0uOaab0kXSrpZUn/ktS/mEidFM2sYzQ0Fl4Ku55sNqK8s4CHIqIv8FB6DXAA0Dctp5DNoVk4zGJ2MjNrH2XN50JLARHxMNl0dHmDgeHp+XCWTrQ8GLghMk8APSWtX+gYTopmVn6i2OZzb0ljcsspBUoGWDciJgOkx3XS+g3J5hRt8jbL3uqiRT7RYmYdQNBQVLqZFhEDS3fQTyk4gaxrimbWMRpUeGmb95uaxelxSlr/NrBxbr+NKOKeRE6KZlZ+TUNy2tmnuBx/Boak50OAu3Prj0tnoXcBZjY1s1vj5rOZdYwSXNEi6WZgEFnf49vAucBFwG2ShgJvAoen3e8DDgReJrs97gnFHMNJ0cw6QGmuaImIo5azaZ8W9g3g9BU9hpOimXWMGrmixUnRzMqvyCtWqoGTopl1DE8IYWbWRG4+m5ktw81nM7NERV/RUnG1EaWZ1T7XFM3MctynaGaW+G5+ZmbNuPlsZraUnBTNzDISqO1Tg3UoJ0Uz6wByTdHMLM9J0cwsp6HBQ3LMzDKi5TumVCEnRTMrO7lP0cxsWW4+m5nluKZoZtbEfYpmZksJuflsZpbn5rOZWV5t5EQnRTPrAHJN0cxsGe5TNDNLPHjbyuqqc4/mgD37MXX6LAYe/nMA1uyxGjdefCKbbtCLN96dzjHfv5YZs+awx4C+3H7JKbz+7gcA3P338fzi6vsrGX5dmzt3LvvvO4h58+axcOFCDjn0MH70k/MqHVZ1qI2cSG3UZ20ZN/7lCQaffsUy6757whcZ+eSL/NvgCxj55It894T9lmx79OlX2OXIi9jlyIucEMtslVVW4Z77/8bjTz3NY0+O428jHuDJ0U9UOqzKU9Z8LrRUg+qIwlbIo+NeYfrMT5ZZd9Cg7bjpL6MBuOkvozl47+0qEVqnJ4lu3boBsGDBAhYsWFAzzcZyk1RwKbKcb0uaKGmCpJslrSppM0mjJU2SdKukldsap5NinVhnre68N+0jAN6b9hFr9+q+ZNvnttuM0beexZ8uP43Pbr5epULsNBYtWsRuO/dn843XY+999mWnnT9X6ZCqg4pYChUhbQh8AxgYEf2ARuBI4GLgkojoC3wIDG1rmGVLipL6SJpQgnIGSrq0FDF1RuNfeIutDvwxnzviIq68ZRS3XXJKpUOqe42NjTz25DheeOVNxj71FM9NbPevQc2TVMrmcxegq6QuwGrAZOALwB1p+3DgkLbGWvU1xYgYExHfqHQc1W7KB7NYr3cPANbr3YOp02cBMGv2XGbPmQ/AA488x0pdGlmr5+oVi7Mz6dmzJ3vsuRcjHnyg0qFUhSKbz70ljckty/wVj4h3gF8Cb5Ilw5nAWGBGRCxMu70NbNjWOMudFLtIGi7pX5LukLSapAGSRkkaK+kBSesDSBop6WJJT0p6SdIeaf0gSfek52tLGiFpnKTfSHpDUu9UK31e0jWpr+FBSV3Te3aQ9ESK4S5Ja5b5M1fEvaOe5ZiDs2baMQd/jntG/guAddda2oweuO2mNEh8MGN2RWLsDKZOncqMGTMAmDNnDv/4+0NsudVWFY6qOhSZFKdFxMDccnWzMtYEBgObARsAqwMHtHC4aGuc5R6SsxUwNCIelfQ74HTgUGBwREyVdATwM+DEpngiYmdJBwLnAvs2K+9c4O8R8QtJ+wP5vyJ9gaMi4mRJtwGHATcBNwBnRMQoSRekMr7VPND0Fykrb6VupfjsZTP8F8ezx4C+9O7ZjZfvv5ALr7qPX143gpsuPpEhh+zKW5M/5OjvXwvAofvuyMmH78HCRYuYO3cBx519XYWjr2/vvzeZr510AosWLWLx4sV85bDDOeDAgyodVlUo0d389gVei4ipAJLuBHYDekrqkmqLGwHvtvUA5U6Kb0XEo+n5TcAPgX7AiPRXoZGsCtzkzvQ4FujTQnmfJ0uqRMT9kj7MbXstIsbn3y9pDaBnRIxK64cDt7cUaPqLdDVAw2rrtPmvTEcYcvb1La4/8NTLPrXuqlsf5qpbHy5zRNak379tx6Ojx1Y6jOpTusv83gR2kbQaMAfYBxgD/AP4D+AWYAhwd1sPUO6k2Dy5zAImRsSuy9l/XnpcRMuxtfZTnZd7vgjoWlSEZlZ2Irv3c3tFxGhJdwDjgIXA02SVmXuBWyT9NK27tq3HKHef4iaSmhLgUcATwNpN6yStJGnbFSjvEeA/03v3A1rtH4yImcCHTf2TwLHAqFbeYmZlIRoaCi/FiIhzI2LriOgXEcdGxLyIeDUido6Iz0TE4RExr3BJLSt3UnweGCLpX0Av4DKyKu7Fkp4BxpP1BxTrfGA/SePIOlcnk9U+WzME+J8Uww7ABSv2EcysFEo1eLvcytZ8jojXgW1a2DQe2LOF/Qflnk8j9SlGxEhgZNo0E/j3iFiYapt7p78Ir5P1VTa9/5e55+OBXdrxUcysvVSa5nNHqLUJITYBbpPUAMwHTq5wPGZWBAGNjbWRFWsqKUbEJGDHSsdhZiuuWprHhdRUUjSzGuXms5nZUr6bn5lZM64pmpnluE/RzCyRKHpwdqU5KZpZh6iRiqKTopl1DDefzcyauPlsZrZUqWbJ6QhOimbWAapnwodCnBTNrEPUSE50UjSzDuA+RTOzpbI+RSdFM7MlnBTNzHLcfDYza+Kpw8zMllI9DMmR1KO1N0bER6UPx8zqVWMdNJ8nkt23Of9Jml4H2f1SzMyKUiMVxeUnxYjYuCMDMbP6JdXO2eei5geXdKSkH6bnG0kaUN6wzKzeNDao4FINCiZFSZcDewPHplWfAFeVMygzqz9S4aUaFHP2ebeI6C/paYCImC5p5TLHZWZ1RGRnoGtBMUlxQbr5fABIWgtYXNaozKy+qHqax4UU06d4BfBHYG1J5wOPABeXNSozqzulaj5L6inpDkkvSHpe0q6SekkaIWlSelyzrXEWTIoRcQNwDvBLYDpweETc0tYDmlnnI6BBKrgUaRhwf0RsDWwPPA+cBTwUEX2Bh9LrNin27tSNwAJg/gq8x8xsiYYGFVwKSReV7AlcCxAR8yNiBjAYGJ52Gw4c0uY4iwjiR8DNwAbARsAfJJ3d1gOaWedTTNM5VRR7SxqTW05pVtTmwFTgOklPS/qtpNWBdSNiMkB6XKetsRZzouUYYEBEfJJ9OP0MGAv8oq0HNbPOp8jm8bSIGNjK9i5Af+CMiBgtaRjtaCq3pJim8Bssmzy7AK+WMggzq38l6lN8G3g7Ikan13eQJcn3Ja0PkB6ntDXO1iaEuIRsGM4nwERJD6TX+5GdgTYzK0p2oqX95UTEe5LekrRVRLwI7AM8l5YhwEXp8e62HqO15vOE9DgRuDe3/om2HszMOimVdOqwM4Dfp4tIXgVOIGv13iZpKPAmcHhbC29tQohr21qomVlzpZp5OyLGAy31O+5TivILnmiRtAXwM2AbYNVcYFuWIgAzq3+laj53hGJOtFwPXEf2uQ4AbgM8eNvMVohSE7q1pRoUkxRXi4gHACLilYg4h2zWHDOzokjQKBVcqkEx4xTnKUvhr0g6FXiHdgyMNLPOqUpyXkHFJMVvA92Ab5D1La4BnFjOoMys/lRL87iQgkkxN0hyFksnmjUzWyE1khNbHbx9F2kOxZZExFfKEpGZ1R3V0HyKrdUUL++wKKrMjp/dhEdHd9qPXxWOuO6pSofQqb36weySl1nzzeeIeKgjAzGz+lYrcw4Wc6LFzKxdBHXRfDYzK5kayYnFJ0VJq0TEvHIGY2b1KZtEtjayYjEzb+8s6VlgUnq9vaTLyh6ZmdWVxobCSzUoJoxLgYOADwAi4hl8mZ+ZrYAS37iqrIppPjdExBvNqr6LyhSPmdWpKqkIFlRMUnxL0s5ASGokm+DxpfKGZWb1pF4Gbzc5jawJvQnwPvC3tM7MrGhV0jouqJhrn6cAR3ZALGZWx2qkoljUzNvX0MI10BHR/H6sZmYtqrfB23/LPV8VOBR4qzzhmFldUh3VFCPi1vxrSTcCI8oWkZnVJVEbWbEtl/ltBmxa6kDMrH4J6FIjY3KK6VP8kKV9ig3AdOCscgZlZvWnVi7zazUppnuzbE92XxaAxRGx3IlnzcxaUku3OG01KUZESLorIgZ0VEBmVodUO2efi2nlPympf9kjMbO61VRTLLRUg9bu0dIlIhYCnwdOlvQKMJvs80VEOFGaWdFqpEux1ebzk0B/4JAOisXM6pSonpvdF9JaUhRARLzSQbGYWb0qYfM4TUwzBngnIg6StBlwC9ALGAccGxHz21p+a0lxbUlnLm9jRPyqrQc1s86nhPMlfhN4HuiRXl8MXBIRt0i6ChgKXNnWwls70dIIdAO6L2cxMytK07XPhZaC5UgbAV8CfpteC/gCcEfaZTjt7PJrraY4OSIuaE/hZmZNSlRR/DXwfZZWzNYCZqSTwgBvAxu25wCt1RRro1fUzKqeyJJNoQXoLWlMblkyG5ekg4ApETG2WdHNtesCk9Zqivu0p2AzsyWKv5vftIgYuJxtuwNflnQg2YxdPchqjj1zQwg3At5tT6jLrSlGxPT2FGxm1kRAo1RwaU1EnB0RG0VEH7KJr/8eEUcD/wD+I+02BLi7PbHWyLwVZlbrVMTSRj8AzpT0Mlkf47XtibMtU4eZma2wUo7djoiRwMj0/FVg51KV7aRoZmVXL1e0mJmVTF3Mp2hmViq1kRKdFM2sA0i4+Wxmlufms5lZTm2kRCdFM+sATYO3a4GTopl1iBrJiU6KZtYRhGqkAe2kaGZl5+azmVme3Hw2M1uGk6J1uK+ddCJ/ve8e1l5nHcaOn1DpcDqN1Vdu5Ot79GGTXl2JgMsefo1d+6zJTpv2ZOGi4L1Z87h01GvMnr+o0qFWTC01nz11WB05dsjx3H3P/ZUOo9M5addNGPf2TE6/fQLfunMib8+Yy/h3PuKMOybwzTsn8s7MuRy2w/qVDrPiVMS/auCkWEc+v8ee9OrVq9JhdCpdV2pg2/W7M+LFaQAsXBzMnr+I8e98xOI0Kf5LUz6m9+orVzDK6iAVXqqBm89m7bBe91WYOWcB39hrMzbr1ZVXpn3CNY+/ybyFi5fss8+Wa/PIq517Ins3n9tJ0iBJ96TnX5Z0VqVjMmtJY4PYovfq3P/cFL5913PMXbiYw7Zf2lQ+fIf1WRzBqJc/qGCU1aCYxnN1JM2qTIp5EfHniLio0nGYtWTa7PlMmz2fl6bOBuCx16azRe/VANi771oM3KQn//v3VysZYnUooulcLRXJsiVFSX0kvSDpt5ImSPq9pH0lPSppkqSd0/KYpKfT41YtlHO8pMvT8y0kPSHpKUkXSPo4rR8kaaSkO9Ixf59uko2kfVL5z0r6naRVyvWZrfOZMWch02bPZ8M1VgVguw168NaHc9hxox4ctv36/OzBScxftLhAKfWvFDeu6ijlril+BhgGbAdsDXwV+DzwXeCHwAvAnhGxI/AT4OcFyhsGDIuInfj0bQx3BL4FbANsDuwuaVXgeuCIiPg3sj7U01oqWNIpTfeanTpt6op+zqpw3DFHMWiPXXnpxRfZos9GXP+7dt2/x4p0zaNvcObemzPsK9uy2Vqrcfv4yXxtt03pulIj5x+4FZd8ZVtO+/ymlQ6z4sp446qSKveJltci4lkASROBhyIiJD0L9AHWAIZL6kt2A+uVCpS3K3BIev4H4Je5bU9GxNvpWONT+bNSDC+lfYYDp5PdK3YZEXE1cDXAgAED23Uz7Uq54aabKx1Cp/Ta9Dl850/PLbPu1NuerVA0Vaxasl4B5a4pzss9X5x7vZgsIV8I/CMi+gEHk93guhTHWpTKr5Gvwaz++URLcdYA3knPjy9i/yeAw9LzI4vY/wWgj6TPpNfHAqNWJEAzK40GFV6qQaWT4n8Dv5D0KNBYxP7fIrvp9ZPA+sDM1naOiLnACcDtqcm+GLiqfSGbWZvUSKdi2foUI+J1oF/u9fHL2bZl7m0/TttHsvRG19eTnSyBrFa5S+qXPBIY03z/9PrruecPkZ2EMbMKyXJelWS9AmrtipYBwOVpuM0M4MQKx2Nmxaii5nEhNZUUI+KfwPaVjsPM2sBJ0cysSfWcXS7ESdHMyk7UTvO50mefzayzKMHZZ0kbS/qHpOclTZT0zbS+l6QR6RLiEZLWbGuYTopm1iFKNHh7IfCdiPgssAtwuqRtgLPIrpjrCzyUXreJk6KZdYhSDN6OiMkRMS49nwU8D2wIDCa7jJf0eEjLJRTmPkUzK7/iB2f3ljQm9/rqNC/Bp4uU+pCNQR4NrBsRkyFLnJLWaWuoTopm1iGKbB5Pi4iBBcuSugF/BL4VER+phNOOuflsZmXXdPa5FNc+S1qJLCH+PiLuTKvfl7R+2r4+MKWtsTopmlnHKM3ZZwHXAs9HxK9ym/4MDEnPhwB3tzVMN5/NrEOUaPD27mSzXT2b5k2FbMLqi4DbJA0F3gQOb+sBnBTNrEOUYvB2RDzC8uuU+7T/CE6KZtZRauSKFidFMys7Tx1mZpbnqcPMzJpxUjQza+Kpw8zMlqilqcOcFM2sYzgpmpkt5eazmVmOm89mZk0EJZzIpqycFM2sg9RGVnRSNLOyE64pmpktw32KZmY5PvtsZpZXGznRSdHMyk+eEMLMbFluPpuZ5dVGTnRSNLOO4eazmdkSnjrMzGwJD942M2vGSdHMLMfNZzOzJp4lx8xsKfcpmpk14+azmVmOa4pmZjlOimZmObXSfFZEVDqGqiNpKvBGpeNoh97AtEoH0cnV+newaUSsXarCJN1P9jMpZFpE7F+q47aFk2IdkjQmIgZWOo7OzN9B7WqodABmZtXESdHMLMdJsT5dXekAzN9BrXKfoplZjmuKZmY5TopmZjlOimZmOU6KZmY5ToqdmFQrV6PWL38H1cdJsRPK/SKuupz1Vma5n7XnH6gyHpLTSUn6IvB1YBLZ9aYXpfUK/6coq6afsaR9gOPIvoNXI+IPFQ7NcE2xU5K0C3A5cAPwT2B3SZcDOCGWX0qIe5AN8P4bMA84UNLZlY3MwFX3zqoHcEtE/BFA0uPAbyXtHhGPVja0TmNj4PKIuFHS6sC2wBmS+kbEpArH1qm5ptgJtNBX2AAcL2kDgIiYAryP/0iWTQvfQSNwqqR1I2I2MB7oBqze4cHZMvxL0Ank+q/2BkZExP2SLgUelHQc0BUYCFxTyTjrWfoOPk/2c74H+AOwCXClpDPJEuLGwKLKRWngEy11LdehPxD4DTCW7Izzc8CVZJ38+5P9cbwiIv5csWDrXEqIVwIvkv28bwXGAUeSfQfzgWERcWfFgjTASbHuSepPdlLlOxHxuKQDgS8AU4FLI2KOpNUi4hOfeS4PSf2AYWTfwXhJJwM7Ag9HxC2SVgVWiYiZ/g4qz32KdahZ/9UCoC9wPEBE3AeMIGu6fS/9Qs5J2/zLWCLNvoM+QD/gUICIuAYYAxwk6RhgYUTMTNv8HVSYk2IdahryIenoiHgW+CLQX9I5afsDZP1at0XEXP8ill76DvaVNDgi7gFOAQZKOiVt/x0wChgfEQsrGastyyda6kiuD/FzwJnAYEk9IuJKSScBV0haNSLOiYi/VjjcupT7DrYj67M9RtKhEXG3pMXAiZJWjojLU43RqoxrinUkNyj4WuAiYChwnqRTI+IZ4BvA/pI+40v6yiN3pv9m4Cbgx8CNkg6PiL+QDZg/UNLG/g6qk2uKNU7S+sAREfHrtKoP8PeIGA2MlvQCMFLSgoi4VtIXIuKjSsVbjyStB+wVEbemVdsAf4iIB8mGPT0F3CVpTkTcJemxiHi/YgFbq1xTrH09gAdScgR4C1hfUldJDRHxOFnN8aeSDnFCLIstgWclrZVezyQbjwhASo53A9dI2tcJsbp5SE4dSGeQfwNMj4hvS7ohbRoGrA0cBjxPVoM52SdWSiNdETQoIv4gqStwGdmJk8sljQQmk51gGQB8GZgONETEBZWK2QpzTbFG5fujImIucAmwlqRzIuI44F3gVOCnwBXAG2QDt92PVTpbAydJOjki5gB/BbZLZ/0Hkf1+XQX8H3AdMAVYr1LBWnHcp1ijch36m5FN/fUnSRcDP0qJ8SwAST2A3YGfAMdExOLKRV13Hic7oXV66rO9XtJ84FBJRMQRkhqBNYD+ZFO1HVXBeK0IrinWmKYaYhp2cy2wKXC2pJ9GxESymuGOkppOvCwCNgeOTWMWrZ2avoNUOxxFdvneYZJOSGeY7yQ7w/zNiFhENvnDLmR/lCZWKm4rjvsUa5CknYAjyC4T+7OkTcl+Ee+LiB9L2hbokobhWAk1u558IbAgIiZKOgD4L+COiBguaTDwSkRMSO9bKSIWVDB0K5Kbz7Xpc2Qd9+9KWiUi3pB0KDAiDQz+AXgW7XJICfFLwH8DvwWOk/S9iPhrGpz9fUmN6YqVJd+BE2LtcFKsAbnayebAe+ns5mTga2RjEZ+MiDcl7Uc2/RTg62jLQdJWwPnAwcAewEpkQ22+ERF/SX2IU5r293dQe9x8rhGpeXYh2RnO/sBg4HSy65r/F3jEtZHyyP1RWoVsiNM84LNkQ3B2B04DziHrt/X0azXOJ1pqgKRtgJ8B/0k2MLg3sGpEDAMeIvuF7Fa5COtbSoiHAncA3ycbirM62VUrH5MNd7oD+LhyUVqpuKZYpVK/1KL0fAvg34HXyJpuR0XEK5J2i4jHJG0SEW9WMt56lKsh9gSuJ5sYthtZDX0S2S0cXieblu3oiHjG/bi1z32KVUZS94iYFRGLlM3WvDlZc+18YBqwU0R8LGlP4AeSTnJCLI+UEHcmu2RvbETcDCDpQ+BsstriM8APm870OyHWPifFKiJpNeBeScOAZ8muhHgGeA94E1iZbDzcHLJfyvMiYnKl4q1XuRriLmRnmN8A1pH0CFnf7R2SViKbAefOiPjANcT64eZzlUl9V2cBs4BzIuKJ1Hw+CNiV7FK9l4GH0jAQ/zKWQRocfwHZLQQmSLoQ6EnWd/hYRCyQtGFEvFPRQK3kXFOsMmlqqY/Jfvn2BZ4gqyW+BmwUEd9r2tcJsazWAPYB9gMmkCXIc4AhZCco/+GEWJ989rkKRcQIss774yUdlYbazAD2krRu7jIzJ8QySdN9HQYMlfTV9B1cSNaVMaXVN1tNc/O5ikk6GBgOjCRLineOgy2LAAADdUlEQVRGdr8P6yDK7n54IXBZRFxf4XCsAzgpVjlJXwHOA4ZGxFNuMnc8SV8mmw1nX+D9pqFSVp+cFGuApF4RMb3ScXRmktaOiKmVjsPKz0nRzCzHJ1rMzHKcFM3McpwUzcxynBTNzHKcFA1JiySNlzRB0u3pGuy2ljVI0j3p+ZclndXKvj0l/VcbjnGepO8Wu77ZPtdL+o8VOFYfSRNWNEarXU6KBjAnInaIiH7AfLJboy6hzAr/X4mIP0fERa3s0pPsviZmVcNJ0Zr7J/CZVEN6XtL/AeOAjSXtJ+lxSeNSjbIbgKT9Jb2QZpH5SlNBko6XdHl6vq6kuyQ9k5bdyAZEb5Fqqf+T9vuepKck/UvS+bmyfiTpRUl/A7Yq9CEknZzKeUbSH5vVfveV9E9JL0k6KO3fKOl/csf+Wnt/kFabnBRtCUldgAPIpi2DLPncEBE7ArPJJkTYNyL6A2OAMyWtClzD0nuWLO9m75cCoyJie7LbKUwkmw3olVRL/V66x0xfYGdgB2CApD0lDQCOBHYkS7o7FfFx7oyIndLxngeG5rb1AfYCvgRclT7DUGBmROyUyj9Z0mZFHMfqjGfJMYCuksan5/8ku5/0BsAbEfFEWr8LsA3waJqPYmWym8FvDbwWEZMAJN0EnNLCMb4AHAeQLpObKWnNZvvsl5an0+tuZEmyO3BXRHySjlHMfVD6SfopWRO9G/BAbtttEbEYmCTp1fQZ9gO2y/U3rpGO/VIRx7I64qRokPoU8ytS4pudXwWMiIijmu23A1Cqy6IE/CIiftPsGN9qwzGuBw5Jtwg4HhiU29a8rEjHPiMi8skTSX1W8LhW49x8tmI9Aewu6TOQzRIuaUvgBWCzNBEuwFHLef9DZHe9a+q/60E2kW733D4PACfm+io3lLQO8DBwqKSukrqTNdUL6Q5MTjNkH91s2+GSGlLMmwMvpmOflvZH0paSVi/iOFZnXFO0okTE1FTjulnZrT4hmxn8JUmnkN1GYRrwCNCvhSK+CVwtaSiwCDgtIh6X9Gga8vLX1K/4WeDxVFP9GDgmIsZJuhUYT3ZrgH8WEfKPgdFp/2dZNvm+CIwC1gVOjYi5kn5L1tc4Ls1XORU4pLifjtUTTwhhZpbj5rOZWY6ToplZjpOimVmOk6KZWY6ToplZjpOimVmOk6KZWc7/A9gqy/gscNkvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from viz import plot_confusion_matrix\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plot_confusion_matrix(cm,[\"benigno\", \"maligno\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
